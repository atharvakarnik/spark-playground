{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5041d3a1-3f7d-4668-8301-ea4999479157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f1c0915-14fa-41c3-9f0c-21bffc8bd803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Spark environments\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['SPARK_HOME'] = '/Users/atharvakarnik/spark-3.5.1-bin-hadoop3'\n",
    "os.environ['PYSPARK_PYTHON'] = 'python'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = 'jupyter'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = 'lab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13aa1f9e-9bea-445d-94bf-4a2667daac59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.25</td>\n",
       "      <td>32.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.20</td>\n",
       "      <td>49.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.00</td>\n",
       "      <td>77.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.14</td>\n",
       "      <td>48.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.28</td>\n",
       "      <td>82.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31.67</td>\n",
       "      <td>53.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.32</td>\n",
       "      <td>60.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23.25</td>\n",
       "      <td>73.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34.58</td>\n",
       "      <td>65.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24.98</td>\n",
       "      <td>41.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25.16</td>\n",
       "      <td>65.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>24.69</td>\n",
       "      <td>40.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Temperature_C  Humidity\n",
       "0           23.25     32.28\n",
       "1           20.20     49.00\n",
       "2           35.00     77.27\n",
       "3           22.14     48.56\n",
       "4           28.28     82.33\n",
       "5           31.67     53.59\n",
       "6           31.32     60.72\n",
       "7           23.25     73.61\n",
       "8           34.58     65.37\n",
       "9           24.98     41.08\n",
       "10          25.16     65.70\n",
       "11          24.69     40.31"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating a literally (not truely though) random dataframe\n",
    "\n",
    "rows = np.random.randint(10, 13)\n",
    "data = {\n",
    "    \"Temperature_C\": np.random.uniform(20, 35, size=rows).round(2),\n",
    "    \"Humidity\": np.random.uniform(30, 90, size=rows).round(2)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44eae22c-6d99-4027-b539-0debb558d980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('RandomApp').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31b7cb45-9b9e-4a96-b169-f87c8bccaedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.184.68.157:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>RandomApp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1462afe10>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d85b7e0-bf0a-4941-90e9-6de8daf12240",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "566983f5-ec2e-4f41-8c79-6c42a03bf6f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n",
      "|Temperature_C|Humidity|\n",
      "+-------------+--------+\n",
      "|        23.25|   32.28|\n",
      "|         20.2|    49.0|\n",
      "|         35.0|   77.27|\n",
      "|        22.14|   48.56|\n",
      "|        28.28|   82.33|\n",
      "|        31.67|   53.59|\n",
      "|        31.32|   60.72|\n",
      "|        23.25|   73.61|\n",
      "|        34.58|   65.37|\n",
      "|        24.98|   41.08|\n",
      "|        25.16|    65.7|\n",
      "|        24.69|   40.31|\n",
      "+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38c15a47-0f46-4824-86ca-ffd6fd95cfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Temperature_C: double (nullable = true)\n",
      " |-- Humidity: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aee76191-c9e1-4ba5-862e-9659c440775e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|Temperature_C|\n",
      "+-------------+\n",
      "|        23.25|\n",
      "|         20.2|\n",
      "|         35.0|\n",
      "|        22.14|\n",
      "|        28.28|\n",
      "|        31.67|\n",
      "|        31.32|\n",
      "|        23.25|\n",
      "|        34.58|\n",
      "|        24.98|\n",
      "|        25.16|\n",
      "|        24.69|\n",
      "+-------------+\n",
      "\n",
      "+-------+------------------+------------------+\n",
      "|summary|     Temperature_C|          Humidity|\n",
      "+-------+------------------+------------------+\n",
      "|  count|                12|                12|\n",
      "|   mean|27.043333333333337| 57.48500000000001|\n",
      "| stddev| 4.993907803665898|15.883322013414517|\n",
      "|    min|              20.2|             32.28|\n",
      "|    max|              35.0|             82.33|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Like a SELECT statement from SQL, Like filtering in Pandas...\n",
    "spark_df.select(['Temperature_C']).show()\n",
    "\n",
    "# Printing summary of Spark dataframe\n",
    "spark_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f0e6c51-35ea-4357-9955-07b90f4b2c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+-----------------+\n",
      "|Temperature_C|Humidity|    Temperature_F|\n",
      "+-------------+--------+-----------------+\n",
      "|        23.25|   32.28|            73.85|\n",
      "|         20.2|    49.0|            68.36|\n",
      "|         35.0|   77.27|             95.0|\n",
      "|        22.14|   48.56|           71.852|\n",
      "|        28.28|   82.33|           82.904|\n",
      "|        31.67|   53.59|           89.006|\n",
      "|        31.32|   60.72|           88.376|\n",
      "|        23.25|   73.61|            73.85|\n",
      "|        34.58|   65.37|           94.244|\n",
      "|        24.98|   41.08|           76.964|\n",
      "|        25.16|    65.7|77.28800000000001|\n",
      "|        24.69|   40.31|76.44200000000001|\n",
      "+-------------+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adding temperature in Farenheit\n",
    "spark_df.withColumn('Temperature_F', spark_df.Temperature_C * 1.8 + 32).show()\n",
    "\n",
    "# spark_df.select(['Temperature_C', 'Temperature_F']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "33e5a8d2-8f03-4562-a43a-53b260d2ac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "import math\n",
    "\n",
    "def calculate_heat_index(T, H):\n",
    "    T_F = T * 1.8 + 32\n",
    "    HI_F = -42.379 + 2.04901523 * T_F + 10.14333127 * H - 0.22475541 * T_F * H \\\n",
    "           - 0.00683783 * T_F**2 - 0.05481717 * H**2 + 0.00122874 * T_F**2 * H \\\n",
    "           + 0.00085282 * T_F * H**2 - 0.00000199 * T_F**2 * H**2\n",
    "    HI_C = (HI_F - 32) * 5 / 9\n",
    "    return HI_C\n",
    "\n",
    "heat_index_udf = udf(calculate_heat_index, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f5de55e-9f15-4fce-b020-6e836fc1cb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+------------------+\n",
      "|Temperature_C|Humidity|        realFeel_C|\n",
      "+-------------+--------+------------------+\n",
      "|        23.25|   32.28|  24.8900957115826|\n",
      "|         20.2|    49.0|25.167423271235577|\n",
      "|         35.0|   77.27|54.761525415134585|\n",
      "|        22.14|   48.56|24.975717773182613|\n",
      "|        28.28|   82.33| 33.21652398881414|\n",
      "|        31.67|   53.59| 34.61404159041657|\n",
      "|        31.32|   60.72|35.728184870092875|\n",
      "|        23.25|   73.61| 24.01024547773431|\n",
      "|        34.58|   65.37|46.391980987860045|\n",
      "|        24.98|   41.08| 25.70160238238701|\n",
      "|        25.16|    65.7|26.164984101267674|\n",
      "|        24.69|   40.31| 25.55826723417512|\n",
      "+-------------+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.withColumn('realFeel_C', heat_index_udf(col('Temperature_C'), col('Humidity'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458a3f57-b920-4ac3-8532-4a8d6be60e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61a23b3-82be-4a2f-8af7-c6a804871ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dac7ad-952a-4566-99cf-bca25e4316f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82e49d44-4b56-47a1-a3f6-550c4261f567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Hold up! Do you really want to end Spark sessio? 'Y'/'N' Y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, ending Spark Session :'(\n"
     ]
    }
   ],
   "source": [
    "# To end the session, let's be kind on our kernel :)\n",
    "\n",
    "just_confirming = input(\"Hold up! Do you really want to end Spark sessio? 'Y'/'N'\")\n",
    "if just_confirming == 'Y': \n",
    "    print(\"Alright, ending Spark Session :'(\")\n",
    "    spark.stop()\n",
    "elif just_confirming == 'N': print(\"That was a close call :)\")\n",
    "else: print(\"You may want to read code before executig ~_~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9b83ff-b797-4061-b604-0c2e0efb1f01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
